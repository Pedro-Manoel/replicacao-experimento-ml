# Replica√ß√£o de Experimento ‚Äî Compara√ß√£o entre Modelos Deep Learning e Shallow Learning

Este reposit√≥rio cont√©m os artefatos desenvolvidos para o projeto da disciplina de Aprendizagem de M√°quina, cujo objetivo foi **replicar um experimento reportado em artigo cient√≠fico**, seguindo a **Op√ß√£o 1** das diretrizes do projeto:  
> O artigo original utiliza modelos de *Deep Learning*, e nesta replica√ß√£o foram implementados modelos de *Shallow Learning* para compara√ß√£o dos resultados.


## üìò Estrutura do Projeto

```

‚îú‚îÄ‚îÄ analysis/                  # Arquivos LaTeX e an√°lises complementares geradas automaticamente
‚îú‚îÄ‚îÄ article_code/              # C√≥digo do artigo original
‚îú‚îÄ‚îÄ data/                      # Conjunto de dados utilizados (arquivos CSV por cidade)
‚îú‚îÄ‚îÄ plots/                     # Gr√°ficos e figuras resultantes dos experimentos
‚îú‚îÄ‚îÄ results/                   # Resultados salvos em CSV (m√©tricas de desempenho)
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îú‚îÄ‚îÄ analise_resultados.ipynb   # Notebook de an√°lise comparativa entre abordagens
‚îú‚îÄ‚îÄ replicacao_fiel.ipynb      # Replica√ß√£o fiel do artigo (modelos shallow com setup original)
‚îî‚îÄ‚îÄ replicacao_otimizada.ipynb # Replica√ß√£o otimizada com engenharia de features e tuning

```

## üß© Descri√ß√£o do Projeto

O trabalho prop√µe uma **replica√ß√£o experimental** de um artigo focado em previs√£o com **modelos de Deep Learning**.  
Nesta replica√ß√£o, foram implementados **modelos de Shallow Learning** utilizando os mesmos dados, horizonte de previs√£o e protocolo experimental do estudo original, a fim de **avaliar o impacto da complexidade do modelo sobre o desempenho preditivo**.

Foram conduzidas **duas abordagens experimentais**:

### üîπ Abordagem 1 ‚Äî Replica√ß√£o Fiel
Objetivo: reproduzir o desenho experimental do artigo original da forma mais fiel poss√≠vel, alterando apenas o tipo de modelo.

**Caracter√≠sticas principais:**
- Mesmas *features* ex√≥genas: `ALLSKY_KT`, `T2M`, `RH2M`, `Month`, `WS10M`;
- Defasagem (lag) de 1 dia para previs√£o de `t` a partir de `t‚àí1`;
- Divis√£o *holdout*: √∫ltimos 30 dias para teste;
- Modelos avaliados:
  1. **Ridge Regression**
  2. **Support Vector Regressor (SVR)**
  3. **Random Forest Regressor**
  4. **XGBoost Regressor**
- Normaliza√ß√£o com `MinMaxScaler` (ajustado apenas no treino).

### üîπ Abordagem 2 ‚Äî Replica√ß√£o Otimizada
Objetivo: explorar o potencial m√°ximo dos modelos *shallow*, incorporando engenharia de *features* e otimiza√ß√£o de hiperpar√¢metros.

**Principais diferen√ßas:**
- **Engenharia de Features Avan√ßada:**
  - Features de calend√°rio (`Year`, `Month`, `Day`, `DayOfWeek`, `DayOfYear`, `WeekOfYear`);
  - Representa√ß√£o c√≠clica de vari√°veis sazonais (`Month`, `DayOfYear`, `DayOfWeek`);
  - Lags de 1, 2, 3, 7, 14 e 30 dias para vari√°veis meteorol√≥gicas e alvo;
  - Estat√≠sticas de janelas m√≥veis (m√©dias, desvios, m√°ximos e m√≠nimos) em janelas de 7, 14 e 30 dias.
- **Otimiza√ß√£o de Hiperpar√¢metros:**  
  - `RandomizedSearchCV` com `TimeSeriesSplit (5 splits)` para busca eficiente;
- **Valida√ß√£o Cruzada (Backtesting):**  
  - *Rolling origin* (5 divis√µes) em todo o conjunto temporal para estimar a generaliza√ß√£o.

## ‚öôÔ∏è Requisitos

Para executar os notebooks, √© necess√°rio ter instalado:

```bash
Python >= 3.9
seaborn 
scikit-posthocs
scikit-learn 
matplotlib 
pandas 
numpy 
statsmodels 
xgboost 
scipy
```

## üöÄ Execu√ß√£o

1. **Clonar o reposit√≥rio:**

   ```bash
   git clone https://github.com/Pedro-Manoel/replicacao-experimento-ml.git
   cd replicacao-experimento-ml
   ```

2. **Organizar os dados:**
   Os arquivos CSV das cidades devem estar na pasta `data/`.
   Cada arquivo representa uma cidade diferente usada nos experimentos.

3. **Selecionar a cidade para o experimento:**

   * Os notebooks (`replicacao_fiel.ipynb` e `replicacao_otimizada.ipynb`) operam **com uma cidade por vez**.
   * A cidade √© definida por meio de uma **flag** no c√≥digo (`STATION_SELECTED`).
   * Para rodar outra cidade, basta alterar o valor dessa flag no in√≠cio do notebook e reexecutar.

4. **Executar os experimentos:**

   * Replica√ß√£o fiel:

     ```bash
     jupyter notebook replicacao_fiel.ipynb
     ```
   * Replica√ß√£o otimizada:

     ```bash
     jupyter notebook replicacao_otimizada.ipynb
     ```

5. **An√°lise comparativa:**

   * Execute `analise_resultados.ipynb` para gerar gr√°ficos e tabelas de compara√ß√£o entre abordagens e cidades.

---

## üìä Resultados

* Resultados num√©ricos (M√©tricas) est√£o em:

  ```
  results/
  ```
* Gr√°ficos comparativos e visualiza√ß√µes est√£o em:

  ```
  plots/
  ```
* Arquivos LaTeX auxiliares (usados no relat√≥rio final) est√£o em:

  ```
  analysis/
  ```

---

Perfeito üëç Aqui est√° uma vers√£o **mais enxuta e direta** das principais conclus√µes, mantendo o rigor t√©cnico e clareza:

---

## üß† Principais Conclus√µes

O projeto replicou o artigo *‚ÄúNeural Networks Forecast Models Comparison for the Solar Energy Generation in Amazon Basin‚Äù*, originalmente baseado em *Deep Learning*, aplicando modelos de *Shallow Learning* (SVR, Ridge, Random Forest e XGBoost) sobre as mesmas 12 cidades da Bacia Amaz√¥nica.

1. **Formula√ß√£o do Problema:**
   A an√°lise mostrou que o artigo realiza previs√µes *one-step-ahead* (de *t‚àí1* para *t*), o que caracteriza um problema de regress√£o supervisionada ‚Äî e n√£o uma previs√£o *multi-step* cont√≠nua.

2. **Desempenho dos Modelos Shallow:**
   Nessa formula√ß√£o, os modelos *shallow* (especialmente o SVR) superaram significativamente os modelos *deep*, demonstrando maior estabilidade e menor erro.

3. **Simplicidade Eficiente:**
   A ‚ÄúReplica√ß√£o Fiel‚Äù teve melhor desempenho que a ‚ÄúOtimizada‚Äù, indicando que o sinal *lag-1* √© suficientemente informativo e que *features* adicionais podem introduzir ru√≠do.

4. **Robustez:**
   Os resultados de *backtesting* confirmaram a consist√™ncia e robustez dos modelos *shallow* para previs√µes de irradia√ß√£o solar di√°ria.

Em s√≠ntese, a replica√ß√£o mostrou que, para este problema, **modelos de regress√£o simples superam arquiteturas profundas**, devido √† natureza do conjunto de dados e da formula√ß√£o experimental do artigo original.


